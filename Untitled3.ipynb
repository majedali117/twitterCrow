{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kdsljf   (0, 106)\t0.575037322656692\n",
      "  (0, 109)\t0.8181271768813353\n",
      "  (1, 43)\t0.3501397270985248\n",
      "  (1, 101)\t0.2808924681097842\n",
      "  (1, 111)\t0.31431795088083947\n",
      "  (1, 114)\t0.3884067098299774\n",
      "  (1, 59)\t0.3013937696017455\n",
      "  (1, 49)\t0.3830162408943693\n",
      "  (1, 112)\t0.3884067098299774\n",
      "  (1, 50)\t0.40055789718233564\n",
      "  (2, 106)\t0.4532264104160287\n",
      "  (2, 78)\t0.6586618108349693\n",
      "  (2, 29)\t0.6006250409773144\n",
      "  (3, 48)\t0.5861656349371474\n",
      "  (3, 66)\t0.810191241879799\n",
      "  (4, 90)\t0.5980750858481534\n",
      "  (4, 25)\t0.5930486078961105\n",
      "  (4, 9)\t0.5390728525535391\n",
      "  (5, 106)\t0.6023429703684664\n",
      "  (5, 29)\t0.7982373995546017\n",
      "  (6, 24)\t0.7135037585970381\n",
      "  (6, 10)\t0.7006514015313889\n",
      "  (7, 64)\t0.610872204922957\n",
      "  (7, 77)\t0.7917292146009044\n",
      "  (8, 86)\t0.6782490761160569\n",
      "  :\t:\n",
      "  (988, 40)\t0.5499608770634532\n",
      "  (988, 17)\t0.6132179024207446\n",
      "  (989, 37)\t0.39752708471447085\n",
      "  (989, 84)\t0.5400985049040277\n",
      "  (989, 7)\t0.4296408090845301\n",
      "  (989, 62)\t0.6047103414760147\n",
      "  (990, 58)\t0.6791166570062355\n",
      "  (990, 47)\t0.7340303578031872\n",
      "  (991, 58)\t0.5954509375588183\n",
      "  (991, 17)\t0.5234731050783754\n",
      "  (991, 6)\t0.6094375187169956\n",
      "  (992, 114)\t0.5800210558701041\n",
      "  (992, 92)\t0.5719712838024819\n",
      "  (992, 117)\t0.5800210558701041\n",
      "  (994, 48)\t0.2899200077579955\n",
      "  (994, 12)\t0.41598061220457183\n",
      "  (994, 95)\t0.5590978394743209\n",
      "  (994, 102)\t0.5088846850268941\n",
      "  (994, 40)\t0.41394746358896656\n",
      "  (995, 59)\t0.33848528158742985\n",
      "  (995, 30)\t0.35530126776606313\n",
      "  (995, 108)\t0.4192446191254038\n",
      "  (995, 92)\t0.4301527543950219\n",
      "  (995, 22)\t0.4498532030008043\n",
      "  (995, 47)\t0.44274527241202144\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      3\n",
      "4      3\n",
      "5      1\n",
      "6      1\n",
      "7      2\n",
      "8      2\n",
      "9      3\n",
      "10     3\n",
      "11     1\n",
      "12     3\n",
      "13     1\n",
      "14     3\n",
      "15     2\n",
      "16     1\n",
      "17     1\n",
      "18     2\n",
      "19     1\n",
      "20     2\n",
      "21     1\n",
      "22     2\n",
      "23     2\n",
      "24     3\n",
      "25     2\n",
      "26     3\n",
      "27     1\n",
      "28     3\n",
      "29     2\n",
      "      ..\n",
      "966    3\n",
      "967    3\n",
      "968    3\n",
      "969    3\n",
      "970    2\n",
      "971    1\n",
      "972    3\n",
      "973    1\n",
      "974    2\n",
      "975    1\n",
      "976    1\n",
      "977    1\n",
      "978    1\n",
      "979    3\n",
      "980    1\n",
      "981    2\n",
      "982    3\n",
      "983    2\n",
      "984    3\n",
      "985    3\n",
      "986    2\n",
      "987    1\n",
      "988    1\n",
      "989    2\n",
      "990    2\n",
      "991    1\n",
      "992    1\n",
      "993    2\n",
      "994    2\n",
      "995    1\n",
      "Name: senti, Length: 996, dtype: int64\n",
      "without the missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\majed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy inter-agreement with topics 0.01 missclasification:  99 of 100\n",
      "accuarcy of annotators reliability 0.0\n",
      "accuracy inter-agreement without topics 0.95 missclasification:  5 of 100\n",
      "accuracy inter-agreement then reliability 0.0 missclasification:  100 of 100\n",
      "accuracy Kappa without Topics 0.79 missclasification:  21 of 100\n",
      "accuracy Kappa Topics 0.01 missclasification:  99 of 100\n",
      "accuarcy of annotators reliability 0.0\n",
      "accuracy Kappa then reliability 0.0 missclasification:  100 of 100\n",
      "accuracy Majority Voting 0.92 missclasification:  8 of 100\n",
      "accuracy Majority Voting with Topics 0.16 missclasification:  84 of 100\n",
      "accuarcy of annotators reliability 0.0\n",
      "accuracy Majority Voting then reliability 0.0 missclasification:  100 of 100\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.13514995e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.22414800e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.64070205e-01]\n",
      " [           nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan]\n",
      " [0.00000000e+00 8.30656098e-02 0.00000000e+00 0.00000000e+00\n",
      "  6.51165685e-01 0.00000000e+00 2.56858506e-02 0.00000000e+00\n",
      "  2.21269945e-02 4.50741403e-03 1.84343663e-01 9.10747944e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.99973041e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.01515897e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.02871550e-02 6.77286532e-01 0.00000000e+00\n",
      "  0.00000000e+00 3.84427253e-03 0.00000000e+00 2.36341612e-03\n",
      "  0.00000000e+00 0.00000000e+00 2.96067035e-01 0.00000000e+00]\n",
      " [9.10400703e-04 1.60062677e-01 0.00000000e+00 0.00000000e+00\n",
      "  8.34745488e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.11065758e-02 0.00000000e+00 8.19572892e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.98164622e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.26853548e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 7.46293697e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.35039302e-01]\n",
      " [           nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan]\n",
      " [0.00000000e+00 6.91282529e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00492587e-02 1.36893909e-02 0.00000000e+00\n",
      "  0.00000000e+00 4.71582366e-03 0.00000000e+00 1.23775592e-03\n",
      "  0.00000000e+00 2.06229033e-04 2.78819013e-01 0.00000000e+00]\n",
      " [5.81259185e-03 1.26795368e-03 5.02555944e-03 0.00000000e+00\n",
      "  0.00000000e+00 5.62473668e-01 0.00000000e+00 0.00000000e+00\n",
      "  8.93138420e-02 4.05941914e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.19059083e-02 0.00000000e+00\n",
      "  9.63768921e-02 0.00000000e+00 0.00000000e+00 1.77229394e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 9.71441205e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.69912325e-01 5.58089089e-03\n",
      "  0.00000000e+00 0.00000000e+00 3.05998990e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.79338168e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.82745065e-03\n",
      "  1.82733353e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.86931300e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.09348026e-02 1.09848217e-02\n",
      "  5.19909147e-03 9.25761951e-01 0.00000000e+00 6.14923384e-03]\n",
      " [0.00000000e+00 8.51838494e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.04408390e-01\n",
      "  0.00000000e+00 0.00000000e+00 7.23472328e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.46320115e-02 0.00000000e+00 0.00000000e+00 1.52873036e-01]\n",
      " [9.68922518e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.91238594e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.69059173e-04 0.00000000e+00\n",
      "  2.74732478e-02 0.00000000e+00 0.00000000e+00 4.71229874e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.72764205e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.97805894e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.45715524e-01\n",
      "  0.00000000e+00 0.00000000e+00 2.80822465e-01 0.00000000e+00]\n",
      " [8.99798590e-03 0.00000000e+00 0.00000000e+00 3.12409883e-01\n",
      "  1.30379002e-03 0.00000000e+00 0.00000000e+00 3.68563318e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.74279424e-01 7.02380988e-03\n",
      "  2.03032137e-02 0.00000000e+00 0.00000000e+00 7.11857618e-03]\n",
      " [1.17269368e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.27443786e-03\n",
      "  5.62377050e-03 0.00000000e+00 0.00000000e+00 2.15896074e-02\n",
      "  0.00000000e+00 4.17375565e-03 0.00000000e+00 0.00000000e+00\n",
      "  5.30067256e-01 1.63750357e-02 0.00000000e+00 4.16723444e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.68368687e-01 0.00000000e+00 0.00000000e+00\n",
      "  6.90447829e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.49942727e-04 0.00000000e+00 0.00000000e+00 1.47262808e-03\n",
      "  0.00000000e+00 0.00000000e+00 1.39560913e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.52844899e-03\n",
      "  0.00000000e+00 0.00000000e+00 3.37396677e-01 5.73364325e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.68156731e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.76221727e-03\n",
      "  0.00000000e+00 6.44644173e-01 0.00000000e+00 5.46668338e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 6.43302079e-02\n",
      "  0.00000000e+00 2.51159317e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.23014797e-01 1.99169654e-04 1.22116839e-02\n",
      "  0.00000000e+00 5.85763037e-02 0.00000000e+00 0.00000000e+00\n",
      "  5.21102597e-02 0.00000000e+00 0.00000000e+00 6.44416465e-02]\n",
      " [0.00000000e+00 6.21090444e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.01561861e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 8.02169603e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.97953523e-02]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.98990120e-01 5.83219711e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.31066073e-03 1.28766801e-01 0.00000000e+00\n",
      "  2.88788475e-01 3.47886704e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.75637805e-04 2.19367467e-01 0.00000000e+00]\n",
      " [1.34359555e-02 0.00000000e+00 3.38426706e-04 1.05179083e-02\n",
      "  4.11699403e-02 0.00000000e+00 0.00000000e+00 1.94896831e-02\n",
      "  3.24067990e-03 1.31042440e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.07849913e-02 0.00000000e+00 3.25497697e-02\n",
      "  4.66924913e-02 8.05463046e-01 0.00000000e+00 3.21286347e-03]\n",
      " [0.00000000e+00 6.09208621e-03 0.00000000e+00 1.66456936e-03\n",
      "  3.06462228e-02 0.00000000e+00 1.97848953e-02 3.48181017e-02\n",
      "  7.63849213e-01 1.84567207e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.32945775e-02\n",
      "  2.82589858e-02 0.00000000e+00 7.14067815e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.90829658e-02 0.00000000e+00 5.24105086e-01 0.00000000e+00\n",
      "  0.00000000e+00 8.17444950e-03 0.00000000e+00 0.00000000e+00\n",
      "  7.99363934e-02 4.00906587e-02 3.27683785e-02 1.52378706e-01\n",
      "  8.74273730e-04 3.78777959e-02 0.00000000e+00 0.00000000e+00\n",
      "  2.01855381e-02 1.48975533e-02 4.96282007e-02 0.00000000e+00]]\n",
      "[1, 1, 3, 1, 2, 2, 3, 1, 2, 3, 2, 3, 3, 1, 2, 1, 1, 1, 3, 3, 1, 3, 1, 2, 3, 2, 2, 2]\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.13514995e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.22414800e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.64070205e-01]\n",
      " [           nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan]\n",
      " [0.00000000e+00 8.30656098e-02 0.00000000e+00 0.00000000e+00\n",
      "  6.51165685e-01 0.00000000e+00 2.56858506e-02 0.00000000e+00\n",
      "  2.21269945e-02 4.50741403e-03 1.84343663e-01 9.10747944e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.99973041e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.01515897e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.02871550e-02 6.77286532e-01 0.00000000e+00\n",
      "  0.00000000e+00 3.84427253e-03 0.00000000e+00 2.36341612e-03\n",
      "  0.00000000e+00 0.00000000e+00 2.96067035e-01 0.00000000e+00]\n",
      " [9.10400703e-04 1.60062677e-01 0.00000000e+00 0.00000000e+00\n",
      "  8.34745488e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.11065758e-02 0.00000000e+00 8.19572892e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.98164622e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.26853548e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 7.46293697e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.35039302e-01]\n",
      " [           nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan\n",
      "             nan            nan            nan            nan]\n",
      " [0.00000000e+00 6.91282529e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00492587e-02 1.36893909e-02 0.00000000e+00\n",
      "  0.00000000e+00 4.71582366e-03 0.00000000e+00 1.23775592e-03\n",
      "  0.00000000e+00 2.06229033e-04 2.78819013e-01 0.00000000e+00]\n",
      " [5.81259185e-03 1.26795368e-03 5.02555944e-03 0.00000000e+00\n",
      "  0.00000000e+00 5.62473668e-01 0.00000000e+00 0.00000000e+00\n",
      "  8.93138420e-02 4.05941914e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.19059083e-02 0.00000000e+00\n",
      "  9.63768921e-02 0.00000000e+00 0.00000000e+00 1.77229394e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 9.71441205e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.69912325e-01 5.58089089e-03\n",
      "  0.00000000e+00 0.00000000e+00 3.05998990e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.79338168e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.82745065e-03\n",
      "  1.82733353e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.86931300e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.09348026e-02 1.09848217e-02\n",
      "  5.19909147e-03 9.25761951e-01 0.00000000e+00 6.14923384e-03]\n",
      " [0.00000000e+00 8.51838494e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.04408390e-01\n",
      "  0.00000000e+00 0.00000000e+00 7.23472328e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.46320115e-02 0.00000000e+00 0.00000000e+00 1.52873036e-01]\n",
      " [9.68922518e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.91238594e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.69059173e-04 0.00000000e+00\n",
      "  2.74732478e-02 0.00000000e+00 0.00000000e+00 4.71229874e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.72764205e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.97805894e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.45715524e-01\n",
      "  0.00000000e+00 0.00000000e+00 2.80822465e-01 0.00000000e+00]\n",
      " [8.99798590e-03 0.00000000e+00 0.00000000e+00 3.12409883e-01\n",
      "  1.30379002e-03 0.00000000e+00 0.00000000e+00 3.68563318e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.74279424e-01 7.02380988e-03\n",
      "  2.03032137e-02 0.00000000e+00 0.00000000e+00 7.11857618e-03]\n",
      " [1.17269368e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.27443786e-03\n",
      "  5.62377050e-03 0.00000000e+00 0.00000000e+00 2.15896074e-02\n",
      "  0.00000000e+00 4.17375565e-03 0.00000000e+00 0.00000000e+00\n",
      "  5.30067256e-01 1.63750357e-02 0.00000000e+00 4.16723444e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.68368687e-01 0.00000000e+00 0.00000000e+00\n",
      "  6.90447829e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.49942727e-04 0.00000000e+00 0.00000000e+00 1.47262808e-03\n",
      "  0.00000000e+00 0.00000000e+00 1.39560913e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.52844899e-03\n",
      "  0.00000000e+00 0.00000000e+00 3.37396677e-01 5.73364325e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.68156731e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.76221727e-03\n",
      "  0.00000000e+00 6.44644173e-01 0.00000000e+00 5.46668338e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 6.43302079e-02\n",
      "  0.00000000e+00 2.51159317e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.23014797e-01 1.99169654e-04 1.22116839e-02\n",
      "  0.00000000e+00 5.85763037e-02 0.00000000e+00 0.00000000e+00\n",
      "  5.21102597e-02 0.00000000e+00 0.00000000e+00 6.44416465e-02]\n",
      " [0.00000000e+00 6.21090444e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.01561861e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 8.02169603e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.97953523e-02]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.98990120e-01 5.83219711e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.31066073e-03 1.28766801e-01 0.00000000e+00\n",
      "  2.88788475e-01 3.47886704e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.75637805e-04 2.19367467e-01 0.00000000e+00]\n",
      " [1.34359555e-02 0.00000000e+00 3.38426706e-04 1.05179083e-02\n",
      "  4.11699403e-02 0.00000000e+00 0.00000000e+00 1.94896831e-02\n",
      "  3.24067990e-03 1.31042440e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.07849913e-02 0.00000000e+00 3.25497697e-02\n",
      "  4.66924913e-02 8.05463046e-01 0.00000000e+00 3.21286347e-03]\n",
      " [0.00000000e+00 6.09208621e-03 0.00000000e+00 1.66456936e-03\n",
      "  3.06462228e-02 0.00000000e+00 1.97848953e-02 3.48181017e-02\n",
      "  7.63849213e-01 1.84567207e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.32945775e-02\n",
      "  2.82589858e-02 0.00000000e+00 7.14067815e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.90829658e-02 0.00000000e+00 5.24105086e-01 0.00000000e+00\n",
      "  0.00000000e+00 8.17444950e-03 0.00000000e+00 0.00000000e+00\n",
      "  7.99363934e-02 4.00906587e-02 3.27683785e-02 1.52378706e-01\n",
      "  8.74273730e-04 3.78777959e-02 0.00000000e+00 0.00000000e+00\n",
      "  2.01855381e-02 1.48975533e-02 4.96282007e-02 0.00000000e+00]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a966ad3ba77d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrel_MV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgroundTruth_temp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Majority Voting then reliability'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m \u001b[0mannotator_responses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfillMissingValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannt_responses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'with the missing values'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-a966ad3ba77d>\u001b[0m in \u001b[0;36mfillMissingValues\u001b[1;34m(annt_responses)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingSetArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingSetArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mtext_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainingTarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp_tweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                      \u001b[1;32mif\u001b[0m \u001b[0mannotator_responses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\majed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \"\"\"\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\majed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\users\\majed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\majed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun  6 14:26:57 2018\n",
    "\n",
    "@author: HP\n",
    "\"\"\"\n",
    "\n",
    "#================================Topic Modelling============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.decomposition import NMF\n",
    "from array import array\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import re\n",
    "from random import randrange, uniform\n",
    "from scipy.stats import truncnorm\n",
    "import surprise\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import pandas as pd \n",
    "from scipy.spatial import distance\n",
    "from surprise.model_selection import cross_validate\n",
    "import random\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    " \n",
    "#dataset = pd.read_csv(\"Tweets.csv\")\n",
    "dataset = pd.read_csv(\"finalizedfull.csv\")\n",
    "#data = dataset['text']\n",
    "data = dataset['tweet']\n",
    "#data1=data.reshape(len(dataset),1)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=2000, min_df=10, stop_words='english')\n",
    "X = vectorizer.fit_transform(data)\n",
    "idx_to_word = np.array(vectorizer.get_feature_names())\n",
    "print('kdsljf',X)\n",
    "# apply NMF\n",
    "nmf = NMF(n_components=20, init='nndsvd', random_state=0, max_iter = 200)\n",
    "np_topics1=20\n",
    "#nmf = NMF(n_components=np_topics1)\n",
    "WW=[]\n",
    "WW = nmf.fit_transform(X)\n",
    "W = np.nan_to_num(WW)\n",
    "tweets_topics=W\n",
    "S=W\n",
    "sum_rows=np.full(len(W),0.0)\n",
    "sum_rows=W.sum(axis=1,dtype=float)\n",
    "'''for i in range(len(W)):\n",
    " for j in range(len(W[i])):\n",
    "   #tweets_topics[i][j]=round(W[i,j]/sum_rows[i],3)\n",
    "   tweets_topics[i][j]=W[i,j]/sum_rows[i]\n",
    "data_temp=data[:10]\n",
    "'''\n",
    "tweets_topics=np.full((100,np_topics1),0.0)   \n",
    "for i in range(100):\n",
    " for j in range(len(W[0])):\n",
    "   tweets_topics[i][j]=(float(W[i,j])/sum_rows[i])\n",
    "H = nmf.components_\n",
    "#=============================End Topic Modelling==================================\n",
    "\n",
    "#===================================Ground Truth====================================\n",
    "#dataset = pd.read_csv(\"Tweets.csv\")\n",
    "dataset = pd.read_csv(\"finalizedfull.csv\")\n",
    "#documents = dataset[['airline_sentiment','text']]\n",
    "documents = dataset[['tweet','senti']]\n",
    "\n",
    "documents.replace({0: 1, 4: 2, 2: 3}, inplace=True)\n",
    "#groundTruth=documents['airline_sentiment']\n",
    "groundTruth=documents['senti']\n",
    "print(groundTruth)\n",
    "groundTruth_temp=groundTruth[:100]\n",
    "np_tweets=len(tweets_topics)\n",
    "np_topics=len(tweets_topics[0])\n",
    "nb_annotators=10\n",
    "nb_labels=3\n",
    "annt_responses=np.full((nb_annotators,np_tweets),0)\n",
    "annt_topics=np.full((nb_annotators,np_topics),1.0)\n",
    "trueLabels=[]\n",
    "topics=np.zeros(np_topics)\n",
    "for i in range(0,np_topics):\n",
    "   for j in range(0,np_tweets):\n",
    "        topics[i]=topics[i]+tweets_topics[j,i]\n",
    "normalizingFactor=topics.sum()\n",
    "#========================================================================\n",
    "\n",
    "def simulateLabels(groundTruth,tweets_topics,topics,numberAnnotators,meanAccuarcy,SdAccuracy,meanLikelihood):\n",
    "  x=[]\n",
    "  likelihood=[]\n",
    "  numberTopics=len(tweets_topics[0])\n",
    "  numberTweets=len(tweets_topics)\n",
    "    \n",
    "  for m in range(0,numberAnnotators):\n",
    "   done=False\n",
    "   while(done==False):\n",
    "    val=np.random.normal(meanAccuarcy, SdAccuracy,1)#the accurcy for each annotater\n",
    "    if val>0 and val<1:\n",
    "        x.append(val)\n",
    "        done=True\n",
    "\n",
    "  for m in range(0,numberAnnotators):\n",
    "   done=False\n",
    "   while(done==False):\n",
    "    #val=np.random.normal(meanLikelihood,SdLikelihood,1)#the Likelihood of response for each annotater\n",
    "    val=np.random.exponential(meanLikelihood,1)\n",
    "    if val>0.0 and val<1.0:\n",
    "       likelihood.append(val)\n",
    "       done=True\n",
    "       \n",
    "  for m in range(0,numberAnnotators):\n",
    "   done=False\n",
    "   while(done==False):\n",
    "    if x[m]>0.0 and x[m]<1.0:\n",
    "     for i in range(0,numberTweets):\n",
    "        correct=np.random.binomial(1,x[m],1)\n",
    "        annotate=np.random.binomial(1,likelihood[m],1)\n",
    "        if (annotate[0]!=0.0):\n",
    "         if correct[0]==1:   \n",
    "          annt_responses[m,i]=groundTruth[i]\n",
    "          for c in range(0,numberTopics):\n",
    "                if tweets_topics[i,c]!=0.0:\n",
    "                    #annt_topics[m,c]=round(annt_topics[m,c]+(tweets_topics[i,c]/topics[c]),4)\n",
    "                    annt_topics[m,c]=round(annt_topics[m,c]+(tweets_topics[i,c]),4)\n",
    "                    \n",
    "         else:\n",
    "           annt_responses[m,i]=randrange(1,nb_labels+1,1)  \n",
    "           if annt_responses[m,i]==groundTruth[i]:\n",
    "               for c in range(0,np_topics):\n",
    "                if tweets_topics[i,c]!=0.0:\n",
    "                    #annt_topics[m,c]=round(annt_topics[m,c]+(tweets_topics[i,c]/topics[c]),4)\n",
    "                    annt_topics[m,c]=round(annt_topics[m,c]+(tweets_topics[i,c]),4)\n",
    "           else:\n",
    "               for c in range(0,numberTopics):\n",
    "                if tweets_topics[i,c]!=0.0:\n",
    "                    #annt_topics[m,c]=round(annt_topics[m,c]-(tweets_topics[i,c]/topics[c]),4)\n",
    "                    annt_topics[m,c]=round(annt_topics[m,c]-(tweets_topics[i,c]),4)\n",
    "             \n",
    "    done=True\n",
    "  return (annt_topics,annt_responses)\n",
    "\n",
    "\n",
    "#===========generate labels===============================       \n",
    "def fillMissingValues(annt_responses):\n",
    "        annotator_responses=[]\n",
    "        annotator_responses=annt_responses\n",
    "        for i in range(0,nb_annotators):\n",
    "            \n",
    "            trainingSet=[]\n",
    "           \n",
    "            trainingTarget=[]\n",
    "            test=[]\n",
    "            accuracy=0\n",
    "            f=0\n",
    "            for j in range(0,np_tweets):\n",
    "                 if annotator_responses[i][j]!= 0:\n",
    "                    trainingSet.append(tweets_topics[j].reshape(-1))\n",
    "                    trainingTarget.append(annotator_responses[i][j])\n",
    "            text_clf= MultinomialNB()\n",
    "            trainingSetArray=np.asarray(trainingSet)\n",
    "            print(trainingSetArray)\n",
    "            print(trainingTarget)\n",
    "            if(len(trainingSetArray)!=0):\n",
    "                print(trainingSetArray)\n",
    "                text_clf = text_clf.fit( np.asarray(trainingSet),trainingTarget)\n",
    "                for j in range(0,np_tweets):\n",
    "                     if annotator_responses[i][j]== 0:\n",
    "                       test=[]\n",
    "                       test.append(tweets_topics[j])\n",
    "                       predicted = text_clf.predict(test)\n",
    "                       annotator_responses[i][j]=predicted[0]\n",
    "                       if annt_responses[i][j]==groundTruth[j]:\n",
    "                            accuracy=accuracy+1\n",
    "                       f=f+1 \n",
    "        return annotator_responses\n",
    "#==========================inter-agreement===========================================\n",
    "\n",
    "def inter_agreement(annotators_responses,numberTopics):\n",
    "  nb_annotators=len(annotators_responses)\n",
    "  np_tweets=len(annotators_responses[0])\n",
    "  agree=[]\n",
    "  for i in range(0,nb_annotators):\n",
    "    agreement=0.0\n",
    "    for j in range(0,nb_annotators):\n",
    "      for z in range(0,np_tweets):\n",
    "        if annt_responses[i][z]!=0:\n",
    "         if annt_responses[i][z]==annt_responses[j][z] and i!=j:\n",
    "           agreement=agreement+1\n",
    "    agree.append(agreement/(np_tweets))\n",
    "  return agree\n",
    "#===============End inter-agreement==================================\n",
    "#=============== Kappa inter-agreement=============================\n",
    "def kappa_aggreement(annt_responses,nb_labels):\n",
    "    kappa_agree=[]\n",
    "    nb_annotators=len(annt_responses)\n",
    "    np_tweets=len(annt_responses[0])\n",
    "    for i in range(0,nb_annotators):\n",
    "     norm=0\n",
    "     for j in range(0,nb_annotators):\n",
    "        kappa=0.0\n",
    "        common=False\n",
    "        confusion=np.full((nb_labels,nb_labels),0)\n",
    "        for z in range(0,np_tweets):\n",
    "            for l in range(1,nb_labels+1):\n",
    "               if annt_responses[i][z]!=0 and annt_responses[j][z]!=0:\n",
    "                   common=True \n",
    "                   confusion[(annt_responses[i][z])-1][(annt_responses[j][z])-1]=confusion[(annt_responses[i][z])-1][(annt_responses[j][z])-1]+1\n",
    "        if common==True:\n",
    "            norm=norm+1\n",
    "        total=confusion.sum()\n",
    "        pra=0.0\n",
    "        if total!=0.0:\n",
    "         pra=np.trace(confusion)/total\n",
    "        pre=0.0\n",
    "        cols=confusion.sum(axis=0)\n",
    "        rows=confusion.sum(axis=1)\n",
    "        for i in range(0,nb_labels):\n",
    "          if total!=0.0:\n",
    "            pre=pre+(cols[i]*rows[i])/total\n",
    "        if total!=0.0: \n",
    "         pre=pre/total\n",
    "        kappa=kappa+((pra-pre)/(1.0-pre))\n",
    "        if(norm!=0):\n",
    "         kappa_agree.append(kappa/(norm))\n",
    "        else:\n",
    "         kappa_agree.append(0.0)\n",
    "    return kappa_agree\n",
    " \n",
    "#===============End Kappa inter- agreement========================\n",
    "#=====================inter agreement with topics\n",
    "#\n",
    "def interAgreementWithTopics(annt_responses,np_topics,nb_labels):\n",
    "    agree=inter_agreement(annt_responses,np_topics)\n",
    "    trueLabels=[]\n",
    "    np_tweets=len(annt_responses[0])\n",
    "    nb_annotators=len(annt_responses)\n",
    "    annt_tpc=np.full((len(annt_responses),np_topics),1.0)\n",
    "    for i in range(0,np_tweets):\n",
    "     highsim=0.0\n",
    "     truelabel=0\n",
    "     for label in range(1,nb_labels+1):\n",
    "         sim=0.0\n",
    "         for j in range(0,nb_annotators):\n",
    "             if annt_responses[j][i]==label:\n",
    "                 for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                   sim=sim+(agree[j]*annt_tpc[j,c])\n",
    "         if highsim<sim:\n",
    "             truelabel=label\n",
    "             highsim=sim\n",
    "     trueLabels.append(truelabel)\n",
    "     for j in range(0,nb_annotators):\n",
    "      if (annt_responses[j][i]==trueLabels[i]) :\n",
    "              for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                    annt_tpc[j,c]=round(annt_tpc[j,c]+(tweets_topics[i,c]/topics[c]),4)\n",
    "      else:\n",
    "             for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                    annt_tpc[j,c]=round(annt_tpc[j,c]-(tweets_topics[i,c]/topics[c]),4)\n",
    "    return (trueLabels,annt_tpc) \n",
    "#====================End inter agreement with topics=================================================\n",
    "#============Kappa with topics============================\n",
    "def kappaInteragreemtWithTopics(annt_responses,nb_labels,tweets_topics):\n",
    "    kappa_agree=kappa_aggreement(annt_responses,nb_labels)\n",
    "    nb_annotators=len(annt_responses)\n",
    "    np_tweets=len(annt_responses[0])\n",
    "    np_topics=len(tweets_topics[0])\n",
    "    annt_tpc_kappa=np.full((nb_annotators,np_topics),1.0)\n",
    "    Kappa_trueLabels=[]\n",
    "    for i in range(0,np_tweets):\n",
    "     highsim=0.0\n",
    "     truelabel=0\n",
    "     for label in range(1,nb_labels+1):\n",
    "         sim=0.0\n",
    "         for j in range(0,nb_annotators):\n",
    "             if annt_responses[j][i]==label:\n",
    "                 for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                   sim=sim+(kappa_agree[j]*annt_tpc_kappa[j,c])\n",
    "         if highsim<sim:\n",
    "             truelabel=label\n",
    "             highsim=sim\n",
    "     Kappa_trueLabels.append(truelabel)\n",
    "     for j in range(0,nb_annotators):\n",
    "      if (annt_responses[j][i]==trueLabels[i]) :\n",
    "              for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                    annt_tpc_kappa[j,c]=round(annt_tpc_kappa[j,c]+(tweets_topics[i,c]/topics[c]),4)\n",
    "      else:\n",
    "             for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                    annt_tpc_kappa[j,c]=round(annt_tpc_kappa[j,c]-(tweets_topics[i,c]/topics[c]),4)\n",
    "    return(Kappa_trueLabels,annt_tpc_kappa)\n",
    "#==============End Kappa with topics=================================\n",
    "#=======================inter agreement without topics===============================\n",
    "def interAgreementWithoutTopics(annt_responses,nb_labels):\n",
    "    trueLabelsWithoutTopics=[]\n",
    "    agree=inter_agreement(annt_responses,np_topics)\n",
    "    for i in range(0,np_tweets):\n",
    "     highsim=0.0\n",
    "     truelabel=0\n",
    "     for label in range(1,nb_labels+1):\n",
    "         sim=0.0\n",
    "         for j in range(0,nb_annotators):\n",
    "             if annt_responses[j][i]==label:\n",
    "                 for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                   sim=sim+agree[j]\n",
    "         if highsim<sim:\n",
    "             truelabel=label\n",
    "             highsim=sim\n",
    "     trueLabelsWithoutTopics.append(truelabel)\n",
    "    return trueLabelsWithoutTopics\n",
    "#======================End inter agreement without topics\n",
    "def reliability_interAgreement(trueLabels,tweets_topics,annt_responses,topics,nb_labels):\n",
    "    nb_annotators=len(annt_responses)\n",
    "    np_topics=len(tweets_topics[0])\n",
    "    annt_tpc2=np.full((nb_annotators,np_topics),1.0)\n",
    "    trueLabels=interAgreementWithoutTopics(annt_responses,nb_labels)\n",
    "    agree=inter_agreement(annt_responses,np_topics)\n",
    "    for j in range(0,len(annt_responses)):\n",
    "      for i in range(0,len(annt_responses[0])):\n",
    "          if (annt_responses[j][i]==trueLabels[i]) :\n",
    "                  for c in range(0,np_topics):\n",
    "                      if tweets_topics[i,c]!=0.0:\n",
    "                        annt_tpc2[j,c]=round(annt_tpc2[j,c]+(tweets_topics[i,c]/topics[c]),4)\n",
    "          else:\n",
    "                 for c in range(0,np_topics):\n",
    "                      if tweets_topics[i,c]!=0.0:\n",
    "                        annt_tpc2[j,c]=round(annt_tpc2[j,c]-(tweets_topics[i,c]/topics[c]),4)\n",
    "\n",
    "    trueLabels_agree_rel=[]\n",
    "    for i in range(0,np_tweets):\n",
    "     highsim=0.0\n",
    "     truelabel=0\n",
    "     for label in range(1,nb_labels+1):\n",
    "         sim=0.0\n",
    "         for j in range(0,nb_annotators):\n",
    "             if annt_responses[j][i]==label:\n",
    "                 for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                   sim=sim+(agree[j]*annt_tpc2[j,c])\n",
    "         if highsim<sim:\n",
    "             truelabel=label\n",
    "             highsim=sim\n",
    "     trueLabels_agree_rel.append(truelabel)\n",
    "    return(trueLabels_agree_rel)\n",
    "trueLabels_agree_rel=reliability_interAgreement(trueLabels,tweets_topics,annt_responses,topics,nb_labels)\n",
    "#====================End intr agreement then reliability=========================\n",
    "#============Kappa without topics============================\n",
    "def kappaInterAgreementWithoutTopics(annt_responses,nb_labels):\n",
    "    Kappa_trueLabelsWithoutTopics=[]\n",
    "    kappa_agree=kappa_aggreement(annt_responses,nb_labels)\n",
    "    np_tweets=len(annt_responses[0])\n",
    "    nb_annotators=len(annt_responses)\n",
    "    for i in range(0,np_tweets):\n",
    "     highsim=0.0\n",
    "     truelabel=0\n",
    "     for label in range(1,nb_labels+1):\n",
    "         sim=0.0\n",
    "         for j in range(0,nb_annotators):\n",
    "             if annt_responses[j][i]==label:\n",
    "                 for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                   sim=sim+(kappa_agree[j])\n",
    "         if highsim<sim:\n",
    "             truelabel=label\n",
    "             highsim=sim\n",
    "     Kappa_trueLabelsWithoutTopics.append(truelabel)\n",
    "    return Kappa_trueLabelsWithoutTopics\n",
    "#==============End Kappa without topics=================================\n",
    "#====================Kappa interagreement then reliability==================\n",
    "def reliability_kappaInterAgreement(tweets_topics,annt_responses,nb_labels):\n",
    "    np_topics=len(tweets_topics[0])\n",
    "    Kappa_annt_tpc2=np.full((nb_annotators,np_topics),1.0)\n",
    "    kappa_agree=kappa_aggreement(annt_responses,nb_labels)\n",
    "    np_tweets=len(annt_responses[0])\n",
    "    Kappa_trueLabelsWithoutTopics=kappaInterAgreementWithoutTopics(annt_responses,nb_labels)\n",
    "    for j in range(0,nb_annotators):\n",
    "     for i in range(0,np_tweets):\n",
    "      if (annt_responses[j][i]==Kappa_trueLabelsWithoutTopics[i]) :\n",
    "              for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                    Kappa_annt_tpc2[j,c]=round(Kappa_annt_tpc2[j,c]+(tweets_topics[i,c]/topics[c]),4)\n",
    "      else:\n",
    "             for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                    Kappa_annt_tpc2[j,c]=round(Kappa_annt_tpc2[j,c]-(tweets_topics[i,c]/topics[c]),4)\n",
    "    \n",
    "    kappa_trueLabels_agree_rel=[]\n",
    "     \n",
    "    for i in range(0,np_tweets):\n",
    "     highsim=0.0\n",
    "     truelabel=0\n",
    "     for label in range(1,nb_labels+1):\n",
    "         sim=0.0\n",
    "         for j in range(0,nb_annotators):\n",
    "             if annt_responses[j][i]==label:\n",
    "                 for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                   sim=sim+(kappa_agree[j]*Kappa_annt_tpc2[j,c])\n",
    "         if highsim<sim:\n",
    "             truelabel=label\n",
    "             highsim=sim\n",
    "     kappa_trueLabels_agree_rel.append(truelabel)\n",
    "    return kappa_trueLabels_agree_rel\n",
    "#====================End Kappa intr agreement then reliability=========================\n",
    "#===========Majority Voting===============================\n",
    "def majorityVoting(annt_responses,nb_labels):\n",
    "    majority_voting=[]\n",
    "    np_tweets=len(annt_responses[0])\n",
    "    nb_annotators=len(annt_responses)\n",
    "    for j in range(0,np_tweets):\n",
    "            high=0\n",
    "            s=0\n",
    "            for x in range(1,nb_labels+1):\n",
    "             s=0\n",
    "             for i in range(0,nb_annotators):\n",
    "                if annt_responses[i][j]==x:\n",
    "                    s=s+1\n",
    "             if s>high:\n",
    "              high=s\n",
    "              majority=x\n",
    "            majority_voting.append(majority)\n",
    "    return majority_voting\n",
    "\n",
    "def reliability_majority_voting(majority_voting,tweets_topics,annt_responses,topics,nb_labels):\n",
    "    nb_annotators=len(annt_responses)\n",
    "    np_topics=len(tweets_topics[0])\n",
    "    annt_tpc2=np.full((nb_annotators,np_topics),1.0)\n",
    "    trueLabels=majority_voting\n",
    "    for j in range(0,len(annt_responses)):\n",
    "      for i in range(0,len(annt_responses[0])):\n",
    "          if (annt_responses[j][i]==trueLabels[i]) :\n",
    "                  for c in range(0,np_topics):\n",
    "                      if tweets_topics[i,c]!=0.0:\n",
    "                        annt_tpc2[j,c]=round(annt_tpc2[j,c]+(tweets_topics[i,c]/topics[c]),4)\n",
    "          else:\n",
    "                 for c in range(0,np_topics):\n",
    "                      if tweets_topics[i,c]!=0.0:\n",
    "                        annt_tpc2[j,c]=round(annt_tpc2[j,c]-(tweets_topics[i,c]/topics[c]),4)\n",
    "\n",
    "    trueLabels_agree_rel=[]\n",
    "    for i in range(0,np_tweets):\n",
    "     highsim=0.0\n",
    "     truelabel=0\n",
    "     for label in range(1,nb_labels+1):\n",
    "         sim=0.0\n",
    "         for j in range(0,nb_annotators):\n",
    "             if annt_responses[j][i]==label:\n",
    "                 for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                   sim=sim+annt_tpc2[j,c]\n",
    "         if highsim<sim:\n",
    "             truelabel=label\n",
    "             highsim=sim\n",
    "     trueLabels_agree_rel.append(truelabel)\n",
    "    return(trueLabels_agree_rel)\n",
    "\n",
    "def mvWithTopics(annt_responses,np_topics,nb_labels):\n",
    "    np_tweets=len(annt_responses[0])\n",
    "    trueLabels=[]\n",
    "    nb_annotators=len(annt_responses)\n",
    "    annt_tpc=np.full((len(annt_responses),np_topics),1.0)\n",
    "    for i in range(0,np_tweets):\n",
    "     highsim=0.0\n",
    "     truelabel=0\n",
    "     for label in range(1,nb_labels+1):\n",
    "         sim=0.0\n",
    "         for j in range(0,nb_annotators):\n",
    "             if annt_responses[j][i]==label:\n",
    "                 for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                   sim=sim+(annt_tpc[j,c])\n",
    "         if highsim<sim:\n",
    "             truelabel=label\n",
    "             highsim=sim\n",
    "     trueLabels.append(truelabel)\n",
    "     for j in range(0,nb_annotators):\n",
    "      if (annt_responses[j][i]==trueLabels[i]) :\n",
    "              for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                    #annt_tpc[j,c]=round(annt_tpc[j,c]+(tweets_topics[i,c]/topics[c]),4)\n",
    "                    annt_tpc[j,c]=round(annt_tpc[j,c]+(tweets_topics[i,c]),4)\n",
    "      else:\n",
    "             for c in range(0,np_topics):\n",
    "                  if tweets_topics[i,c]!=0.0:\n",
    "                    #annt_tpc[j,c]=round(annt_tpc[j,c]-(tweets_topics[i,c]/topics[c]),4)\n",
    "                    annt_tpc[j,c]=round(annt_tpc[j,c]-(tweets_topics[i,c]),4)\n",
    "    return (trueLabels,annt_tpc) \n",
    "def accuracy(trueLabels,groundTruth,text):\n",
    "    hits=0\n",
    "    np_tweets=len(trueLabels)\n",
    "    for i in range(0,np_tweets):\n",
    "     if groundTruth[i]==trueLabels[i]:\n",
    "        hits=hits+1\n",
    "    print('accuracy',text,(float(hits)/float(np_tweets)),'missclasification: ',np_tweets-hits,'of',np_tweets)\n",
    "def compareReliability(realAnntTopics,estAnntTopics):\n",
    "        nb_annotators=len(realAnntTopics)\n",
    "        np_topics=len(realAnntTopics[0])\n",
    "        unbiased_annt_topics=np.full((nb_annotators,np_topics),' ')\n",
    "        unbiased_annt_tpcs=np.full((nb_annotators,np_topics),' ')\n",
    "        for i in range(0,nb_annotators):\n",
    "            for j in range(0,np_topics):\n",
    "                if realAnntTopics[i][j]-realAnntTopics.mean()>0.0:\n",
    "                     unbiased_annt_topics[i][j]='r'\n",
    "                else:\n",
    "                     unbiased_annt_topics[i][j]='u'\n",
    "                if estAnntTopics[i][j]-estAnntTopics.mean()>0.0:\n",
    "                     unbiased_annt_tpcs[i][j]='r'\n",
    "                else:\n",
    "                     unbiased_annt_tpcs[i][j]='u'\n",
    "        for i in range(0,nb_annotators):\n",
    "           spammer=True\n",
    "           for j in range(0,np_topics):       \n",
    "               if unbiased_annt_topics[i][j]=='r':\n",
    "                spammer=False\n",
    "           if spammer==True:\n",
    "               for c in range(0,np_topics):\n",
    "                   unbiased_annt_topics[i][c]='s'\n",
    "                   \n",
    "        for i in range(0,nb_annotators):\n",
    "           spammer=True\n",
    "           for j in range(0,np_topics):       \n",
    "               if unbiased_annt_tpcs[i][j]=='r':\n",
    "                spammer=False\n",
    "           if spammer==True:\n",
    "               for c in range(0,np_topics):\n",
    "                   unbiased_annt_tpcs[i][c]='s'\n",
    "        '''print('Real Reliability of annotators')\n",
    "        print(unbiased_annt_topics)\n",
    "        print('Estimated Reliability of annotators')\n",
    "        print(unbiased_annt_tpcs)\n",
    "        '''\n",
    "        counter=0\n",
    "        for i in range(0,nb_annotators):\n",
    "            for j in range(0,np_topics):\n",
    "                if unbiased_annt_tpcs[i][j]!=unbiased_annt_topics[i][j]:\n",
    "                    counter=counter+1\n",
    "        print('accuarcy of annotators reliability',counter/(nb_annotators*np_topics))\n",
    "#========================accuracy======================================\n",
    "\n",
    "print('without the missing values')\n",
    "meanAccuarcy=0.7\n",
    "SdAccuracy=0.1\n",
    "meanLikelihood=1.0\n",
    "(annt_topics,annt_responses)=simulateLabels(groundTruth,tweets_topics,topics,nb_annotators,meanAccuarcy,SdAccuracy,meanLikelihood)\n",
    "agree=inter_agreement(annt_responses,np_topics)\n",
    "(trueLabels,annt_tpc)=interAgreementWithTopics(annt_responses,np_topics,nb_labels)\n",
    "(Kappa_trueLabels,annt_tpc_kappa)=kappaInteragreemtWithTopics(annt_responses,nb_labels,tweets_topics)\n",
    "trueLabelsWithoutTopics=interAgreementWithoutTopics(annt_responses,nb_labels)\n",
    "Kappa_trueLabelsWithoutTopics=kappaInterAgreementWithoutTopics(annt_responses,nb_labels)\n",
    "kappa_trueLabels_agree_rel= reliability_kappaInterAgreement(tweets_topics,annt_responses,nb_labels)\n",
    "majority_voting=majorityVoting(annt_responses,nb_labels)\n",
    "rel_MV=reliability_majority_voting(majority_voting,tweets_topics,annt_responses,topics,nb_labels)\n",
    "(mv_withTopics,mv_annt_tpc)=mvWithTopics(annt_responses,np_topics,nb_labels) \n",
    "accuracy(trueLabels,groundTruth_temp,'inter-agreement with topics')\n",
    "compareReliability(annt_topics,annt_tpc)\n",
    "accuracy(trueLabelsWithoutTopics,groundTruth_temp,'inter-agreement without topics')\n",
    "accuracy(trueLabels_agree_rel,groundTruth_temp,'inter-agreement then reliability')\n",
    "accuracy(Kappa_trueLabelsWithoutTopics,groundTruth_temp,'Kappa without Topics')\n",
    "accuracy(Kappa_trueLabels,groundTruth_temp,'Kappa Topics')\n",
    "compareReliability(annt_topics,annt_tpc_kappa)\n",
    "accuracy(kappa_trueLabels_agree_rel,groundTruth_temp,'Kappa then reliability')\n",
    "accuracy(majority_voting,groundTruth_temp,'Majority Voting')\n",
    "accuracy(mv_withTopics,groundTruth_temp,'Majority Voting with Topics')\n",
    "compareReliability(annt_topics,mv_annt_tpc)\n",
    "accuracy(rel_MV,groundTruth_temp,'Majority Voting then reliability')\n",
    "\n",
    "annotator_responses=fillMissingValues(annt_responses)\n",
    "print('with the missing values')\n",
    "\n",
    "agree=inter_agreement(annotator_responses,np_topics)\n",
    "(trueLabels,annt_tpc)=interAgreementWithTopics(annotator_responses,np_topics,nb_labels)\n",
    "(Kappa_trueLabels,annt_tpc_kappa)=kappaInteragreemtWithTopics(annotator_responses,nb_labels,tweets_topics)\n",
    "trueLabelsWithoutTopics=interAgreementWithoutTopics(annotator_responses,nb_labels)\n",
    "Kappa_trueLabelsWithoutTopics=kappaInterAgreementWithoutTopics(annotator_responses,nb_labels)\n",
    "kappa_trueLabels_agree_rel= reliability_kappaInterAgreement(tweets_topics,annotator_responses,nb_labels)\n",
    "majority_voting=majorityVoting(annotator_responses,nb_labels)\n",
    "rel_MV=reliability_majority_voting(majority_voting,tweets_topics,annotator_responses,topics,nb_labels)\n",
    "(mv_withTopics,mv_annt_tpc)=mvWithTopics(annotator_responses,np_topics,nb_labels) \n",
    "accuracy(trueLabels,groundTruth_temp,'inter-agreement with topics')\n",
    "accuracy(trueLabelsWithoutTopics,groundTruth_temp,'inter-agreement without topics')\n",
    "accuracy(trueLabels_agree_rel,groundTruth_temp,'inter-agreement then reliability')\n",
    "accuracy(Kappa_trueLabelsWithoutTopics,groundTruth_temp,'Kappa without Topics')\n",
    "accuracy(Kappa_trueLabels,groundTruth_temp,'Kappa Topics')\n",
    "accuracy(kappa_trueLabels_agree_rel,groundTruth_temp,'Kappa then reliability')\n",
    "accuracy(majority_voting,groundTruth_temp,'Majority Voting')\n",
    "accuracy(mv_withTopics,groundTruth_temp,'Majority Voting with Topics')\n",
    "accuracy(rel_MV,groundTruth_temp,'Majority Voting then reliability')\n",
    "\n",
    "\n",
    "#===================End Majority Voting===ُ================================\n",
    "\n",
    "print('number of tweets',np_tweets)\n",
    "print('number of topics',np_topics)\n",
    "print('number of annotators',nb_annotators)\n",
    "#======================================================================\n",
    "count=0\n",
    "for i in range(len(annt_responses)):\n",
    "    for j in range(len(annt_responses[i])):\n",
    "         if annt_responses[i][j]==0:\n",
    "             count=count+1\n",
    "            \n",
    "print ('sparsity of the responses matrix',count/(np_tweets*nb_annotators),'empty:',count,'of ',np_tweets*nb_annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
